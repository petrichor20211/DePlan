{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DePlan Complete Workflow Example\n",
    "\n",
    "This notebook demonstrates the complete workflow of the DePlan project:\n",
    "1. **Task Loading**: Natural language task descriptions example\n",
    "2. **PDDL Generation**: Translating natural language to PDDL problem files using LLM\n",
    "3. **Planning Solving**: Solving PDDL problems using the Fast-Downward solver\n",
    "4. **Result Evaluation**: Analyzing planning results and performance metrics\n",
    "\n",
    "## Example: Blocksworld Domain\n",
    "\n",
    "We will use the first task from the Blocksworld domain as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from agents.deplan.agent import DePlanAgent\n",
    "from envs.pddl.env import PDDLEnv\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Environment and Agent\n",
    "\n",
    "First, we need to:\n",
    "- Initialize the PDDL environment (load domain files and tasks)\n",
    "- Initialize the LLM Agent (configure LLM client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "config = {\n",
    "    \"profile\": \"deepseek\",  # LLM configuration name (needs to be configured in configs/profiles.yaml)\n",
    "    \"domain_name\": \"blocksworld\",\n",
    "    \"task_id\": 0,  # Use the first task\n",
    "    \"use_context\": False,  # Whether to use in-context learning\n",
    "}\n",
    "\n",
    "# Initialize environment\n",
    "print(\"üì¶ Initializing PDDL environment...\")\n",
    "env = PDDLEnv(domain_name=config[\"domain_name\"])\n",
    "\n",
    "# Initialize Agent\n",
    "print(\"ü§ñ Initializing DePlan Agent...\")\n",
    "agent = DePlanAgent(use_context=config[\"use_context\"])\n",
    "\n",
    "print(\"‚úÖ Initialization completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Task\n",
    "\n",
    "The environment will load the specified task, including:\n",
    "- Natural language task description (.nl file)\n",
    "- Standard PDDL problem file (.pddl file, for comparison)\n",
    "- Domain description (domain.nl and domain.pddl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment to load task\n",
    "print(\"üîÑ Loading task...\")\n",
    "init_info = env.reset(config, id=str(config[\"task_id\"]))\n",
    "agent.reset(config, init_info)\n",
    "\n",
    "# Get task information\n",
    "task_nl = init_info[\"observations\"][0]\n",
    "domain_nl = init_info[\"domain_nl\"]\n",
    "domain_pddl = init_info[\"domain_pddl\"]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìù Natural Language Task Description:\")\n",
    "print(\"=\" * 60)\n",
    "print(task_nl)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìö Domain Description (Natural Language):\")\n",
    "print(\"=\" * 60)\n",
    "print(domain_nl[:500] + \"...\" if len(domain_nl) > 500 else domain_nl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display standard PDDL problem file (for comparison)\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã Standard PDDL Problem File (Reference):\")\n",
    "print(\"=\" * 60)\n",
    "print(env.current_task_pddl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: LLM PDDL Generation\n",
    "\n",
    "The Agent uses LLM to translate natural language task descriptions into PDDL problem files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: Display Complete LLM Message\n",
    "\n",
    "Display the complete message sent to the LLM, including the prompt and system message (if any).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the prompt that was sent to LLM\n",
    "task_nl = init_info[\"observations\"][0]\n",
    "if agent.use_context and agent.context:\n",
    "    prompt = agent._build_llm_ic_pddl_prompt(task_nl)\n",
    "else:\n",
    "    prompt = agent._build_llm_pddl_prompt(task_nl)\n",
    "\n",
    "# Build complete messages (including system prompt if any)\n",
    "messages = agent.llm_client._build_messages(prompt, system_prompt=None)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üì® Complete LLM Message:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\")\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"Message {i}:\")\n",
    "    print(f\"  Role: {msg['role']}\")\n",
    "    print(f\"  Content:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(msg['content'])\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\n\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent generates PDDL\n",
    "print(\"üß† LLM is generating PDDL problem file...\")\n",
    "observations = init_info[\"observations\"]\n",
    "actions = await agent.act(observations)\n",
    "\n",
    "generated_pddl = actions[0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Generated PDDL Problem File:\")\n",
    "print(\"=\" * 60)\n",
    "print(generated_pddl)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"üìä Statistics:\")\n",
    "print(f\"   - PDDL length: {len(generated_pddl)} characters\")\n",
    "print(f\"   - LLM query count: {agent.num_queries}\")\n",
    "print(f\"   - LLM cost: ${agent.total_cost:.4f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Planning Solving\n",
    "\n",
    "The environment uses the Fast-Downward solver to solve the generated PDDL problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment solves PDDL\n",
    "print(\"‚öôÔ∏è  Calling Fast-Downward solver...\")\n",
    "observations = await env.run(actions)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üì§ Solver Output:\")\n",
    "print(\"=\" * 60)\n",
    "print(observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Results\n",
    "\n",
    "Check whether planning succeeded and analyze performance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "success = env.is_success()\n",
    "env_report = env.report()\n",
    "agent_report = agent.report()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä Evaluation Results\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ Planning status: {'Success' if success else 'Failed'}\")\n",
    "print(f\"\\nüìà Environment Metrics:\")\n",
    "print(f\"   - Planning cost: {env_report['cost']}\")\n",
    "print(f\"   - Planning time: {env_report['time']:.2f} seconds\")\n",
    "print(f\"   - Number of steps: {env_report['steps']}\")\n",
    "print(f\"   - Task type: {env_report['task_type']}\")\n",
    "print(f\"   - Task ID: {env_report['task_id']}\")\n",
    "\n",
    "print(f\"\\nü§ñ Agent Metrics:\")\n",
    "print(f\"   - LLM query count: {agent_report['llm_queries']}\")\n",
    "print(f\"   - LLM total cost: ${agent_report['llm_cost']:.4f}\")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\nüìã Generated Planning Solution:\")\n",
    "    print(\"=\" * 60)\n",
    "    plan_lines = env.plan.split('\\n') if env.plan else []\n",
    "    for i, line in enumerate(plan_lines[:20], 1):  # Display first 20 lines\n",
    "        print(f\"{i:2d}. {line}\")\n",
    "    if len(plan_lines) > 20:\n",
    "        print(f\"... (total {len(plan_lines)} actions)\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(f\"\\n‚ùå Planning failed, possible reasons:\")\n",
    "    print(\"   - PDDL syntax error\")\n",
    "    print(\"   - Problem is unsolvable\")\n",
    "    print(\"   - Solver timeout\")\n",
    "    print(\"   - Domain and problem mismatch\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Comparative Analysis\n",
    "\n",
    "Compare the differences between the generated PDDL and the standard PDDL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare generated PDDL and standard PDDL\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç PDDL Comparative Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "standard_pddl = env.current_task_pddl.strip()\n",
    "generated_pddl_clean = generated_pddl.strip()\n",
    "\n",
    "print(\"\\nüìã Standard PDDL (Reference):\")\n",
    "print(\"-\" * 60)\n",
    "print(standard_pddl)\n",
    "\n",
    "print(\"\\n\\nü§ñ Generated PDDL:\")\n",
    "print(\"-\" * 60)\n",
    "print(generated_pddl_clean)\n",
    "\n",
    "# Simple similarity check\n",
    "if standard_pddl == generated_pddl_clean:\n",
    "    print(\"\\n‚úÖ Generated PDDL is identical to standard PDDL!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Generated PDDL differs from standard PDDL\")\n",
    "    print(f\"   Standard length: {len(standard_pddl)} characters\")\n",
    "    print(f\"   Generated length: {len(generated_pddl_clean)} characters\")\n",
    "    \n",
    "    # Check key elements\n",
    "    key_elements = [\"define\", \"problem\", \"domain\", \"objects\", \"init\", \"goal\"]\n",
    "    print(\"\\nüîë Key Element Check:\")\n",
    "    for element in key_elements:\n",
    "        in_standard = element in standard_pddl.lower()\n",
    "        in_generated = element in generated_pddl_clean.lower()\n",
    "        status = \"‚úÖ\" if (in_standard == in_generated) else \"‚ùå\"\n",
    "        print(f\"   {status} '{element}': standard={in_standard}, generated={in_generated}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Category                  | Challenge                   | Core Symptom                       | Illustrative Example                                                                      |\n",
    "| :------------------------ | :-------------------------- | :--------------------------------- | :---------------------------------------------------------------------------------------- |\n",
    "| **Syntax Fragility**      | Formal-language errors      | Planner parsing failure            | Missing parentheses or undefined predicates ‚Äî e.g., `(:action pick :precond (holding ?x)` |\n",
    "| **Semantic Gap**          | Action/predicate mismatch   | Inconsistent preconditions/effects | `(open fridge)` without defining the object type or effect `(not (closed fridge))`        |\n",
    "| **Feedback Sparsity**     | Planner only returns *fail* | No informative feedback signal     | ‚ÄúPlan-Not-Found‚Äù without showing which action failed                                      |                  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recode-alfworld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
